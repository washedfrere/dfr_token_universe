# dfr_token_universe
Estudios sobre tokenización de texto

Uso:

Crear un entorno virtual:

```python -m venv venv```

Entrar en el entorno virtual

```./venv/Scripts/activate```

Instalar las dependencias

```pip install -r requierements.txt```

Instalar el paquete en modo editable

```pip install -e .```

## Análisis de textos
Estudios desde varias perspectivas sobre la distribución del texto en diferentes formas
- Usando espacio como parte de la palabra-token
- Separando palabras con espacios
- Separando por diferentes separadores
- etc.

## Análisis de tokens
Diferentes formas de aproximación desde el texto hacia 'tokens' o fragmentos útiles.
- Por apriorismos
- Por estadística
- Por combinatoria

## Meta-análisis de tokens
Relaciones entre fragmentos (tokens) en un texto ya tokenizado
- Secuencias
- Grupos
- Estructuras
