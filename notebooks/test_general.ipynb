{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dfrtokenuniverse.splitter\n",
    "import dfrtokenuniverse.word_inventory\n",
    "import dfrtokenuniverse.constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dfrtokenuniverse.splitter)\n",
    "importlib.reload(dfrtokenuniverse.word_inventory)\n",
    "importlib.reload(dfrtokenuniverse.constantes)\n",
    "from dfrtokenuniverse.splitter import TextSplitter\n",
    "from dfrtokenuniverse.word_inventory import WordInventory\n",
    "from dfrtokenuniverse.constantes import KDfrNlp\n",
    "K = KDfrNlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'esto': 1, 'es': 2, 'una': 2, 'forma': 1, 'de': 1, 'tokenizar': 1, 'hay': 1, 'otra': 1, 'no': 1, 'pues': 1, 'esta': 1, 'más': 1, 'seguro': 1}, 2: {' ': 12, ', ': 1, '\\n': 1}, 3: {'¿': 1, '?': 1, '¡': 1, '!': 1}}\n",
      "Letras contiene 'esto' con 1 apariciones\n",
      "Letras contiene 'es' con 2 apariciones\n",
      "Letras contiene 'una' con 2 apariciones\n",
      "Letras contiene 'forma' con 1 apariciones\n",
      "Letras contiene 'de' con 1 apariciones\n",
      "Letras contiene 'tokenizar' con 1 apariciones\n",
      "Letras contiene 'hay' con 1 apariciones\n",
      "Letras contiene 'otra' con 1 apariciones\n",
      "Letras contiene 'no' con 1 apariciones\n",
      "Letras contiene 'pues' con 1 apariciones\n",
      "Letras contiene 'esta' con 1 apariciones\n",
      "Letras contiene 'más' con 1 apariciones\n",
      "Letras contiene 'seguro' con 1 apariciones\n",
      "Separadores contiene ' ' con 12 apariciones\n",
      "Separadores contiene ', ' con 1 apariciones\n",
      "Separadores contiene '¬' con 1 apariciones\n",
      "Símbolos contiene '¿' con 1 apariciones\n",
      "Símbolos contiene '?' con 1 apariciones\n",
      "Símbolos contiene '¡' con 1 apariciones\n",
      "Símbolos contiene '!' con 1 apariciones\n"
     ]
    }
   ],
   "source": [
    "splitter = TextSplitter()\n",
    "invent = WordInventory()\n",
    "a_dic = {}\n",
    "for ttkn, n_grama in splitter.split_by_type(\"Esto es una forma de tokenizar, hay otra ¿no?\\nPues esta es una más ¡SEGURO!\"):\n",
    "    invent.normalize_and_count(ttkn, n_grama, a_dic)\n",
    "print(a_dic)\n",
    "for ttkn in a_dic:\n",
    "    for n_grama in a_dic[ttkn]:\n",
    "        p_ngrama = n_grama.replace(\"\\n\", \"¬\")\n",
    "        print(f\"{K.TTKN_DESC[ttkn]} contiene '{p_ngrama}' con {a_dic[ttkn][n_grama]} apariciones\")\n",
    "del a_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperamos texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo desde: D:\\datos\\wiki_1909627_entradas.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "wiki_path = r\"D:\\datos\\wiki_1909627_entradas.pkl\"\n",
    "print(f\"Leyendo desde: {wiki_path}\")\n",
    "with open(wiki_path, \"rb\") as wiki_file:\n",
    "    wiki_data = pickle.load(wiki_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos en wiki: 1909627\n"
     ]
    }
   ],
   "source": [
    "print(f\"Documentos en wiki: {len(wiki_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ngramas = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos varias pasadas para ir acumulando n-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "salta  = 200000\n",
    "limite = 210000\n",
    "incremento = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llevamos 230000 entradas de 230000 (100.0%)\n",
      "- 915608 n-gramas recolectados del tipo Letras\n",
      "- 3733 n-gramas recolectados del tipo Separadores\n",
      "- 17216 n-gramas recolectados del tipo Dígitos\n",
      "- 602 n-gramas recolectados del tipo Símbolos\n",
      "- 18109 n-gramas recolectados del tipo Desconocidos\n",
      "- 6 n-gramas recolectados del tipo Especiales\n"
     ]
    }
   ],
   "source": [
    "cont_entradas = 0\n",
    "for entrada in wiki_data:\n",
    "    if cont_entradas > salta:\n",
    "        for ttkn, n_grama in splitter.split_by_type(entrada):\n",
    "            invent.normalize_and_count(ttkn, n_grama, dic_ngramas)\n",
    "        for linea in wiki_data[entrada]:\n",
    "            for ttkn, n_grama in splitter.split_by_type(linea):\n",
    "                invent.normalize_and_count(ttkn, n_grama, dic_ngramas)\n",
    "        if cont_entradas > limite:\n",
    "            break\n",
    "        if cont_entradas % 1000 == 0:\n",
    "            clear_output(True)\n",
    "            print(f\"Llevamos {cont_entradas} entradas de {limite} ({round(100*cont_entradas/limite, 2)}%)\")\n",
    "            for ttkn in dic_ngramas:\n",
    "                print(f\"- {len(dic_ngramas[ttkn])} n-gramas recolectados del tipo {K.TTKN_DESC[ttkn]}\")\n",
    "    cont_entradas += 1\n",
    "salta = limite\n",
    "limite += incremento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contabilizacion de monogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empezando tipo Letras...\n",
      "Empezando tipo Separadores...\n",
      "Empezando tipo Dígitos...\n",
      "Empezando tipo Símbolos...\n",
      "Empezando tipo Desconocidos...\n",
      "Empezando tipo Especiales...\n",
      "Terminado...\n",
      "7635295 para el tipo Letras\n",
      "24294 para el tipo Separadores\n",
      "86995 para el tipo Dígitos\n",
      "1975 para el tipo Símbolos\n",
      "18109 para el tipo Desconocidos\n",
      "57 para el tipo Especiales\n"
     ]
    }
   ],
   "source": [
    "cont_monogramas = {x:{} for x in dic_ngramas}\n",
    "apar_monogramas = {x:0 for x in dic_ngramas}\n",
    "\n",
    "for ttkn in dic_ngramas:\n",
    "    print(f\"Empezando tipo {K.TTKN_DESC[ttkn]}...\")\n",
    "    for n_grama in dic_ngramas[ttkn]:\n",
    "        for caracter in n_grama:\n",
    "            invent._dict_counter(ttkn, caracter, cont_monogramas)\n",
    "            apar_monogramas[ttkn] += 1\n",
    "print(\"Terminado...\")\n",
    "for ttkn in apar_monogramas:\n",
    "    print(f\"{apar_monogramas[ttkn]} para el tipo {K.TTKN_DESC[ttkn]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probabilidad de monogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para          Letras: <a>: 0.1229755, <e>: 0.0906358, <i>: 0.0841251, <o>: 0.0747421, <r>: 0.0731348, <n>: 0.0675889, <s>: 0.0659625, <t>: 0.0523367, <l>: 0.0498435, <c>: 0.0423973\n",
      "Para     Separadores: < >: 0.5441261, <.>: 0.1494196, <\">: 0.0592327, <,>: 0.04816, <->: 0.0365111, <:>: 0.0324772, <'>: 0.0314893, < >: 0.5441261, <_>: 0.017494, <;>: 0.0172882\n",
      "Para         Dígitos: <0>: 0.1493649, <1>: 0.1299385, <2>: 0.1091327, <3>: 0.0940974, <4>: 0.0925685, <5>: 0.0907523, <6>: 0.086959, <7>: 0.0840738, <8>: 0.0817633, <9>: 0.0813495\n",
      "Para        Símbolos: <}>: 0.2794937, <)>: 0.1017722, <{>: 0.0835443, <&>: 0.0789873, <(>: 0.0724051, <]>: 0.0551899, <!>: 0.0516456, <|>: 0.0450633, <?>: 0.038481, <[>: 0.0374684\n",
      "Para    Desconocidos: <ɾ>: 5.52e-05, <ˈ>: 5.52e-05, <ː>: 5.52e-05, <ž>: 5.52e-05, <č>: 5.52e-05, <​>: 5.52e-05, <«>: 5.52e-05, <»>: 5.52e-05, <“>: 5.52e-05, <”>: 5.52e-05\n",
      "Para      Especiales: <\t>: 1.0\n"
     ]
    }
   ],
   "source": [
    "prob_monogramas = {x:{} for x in dic_ngramas}\n",
    "for ttkn in cont_monogramas:\n",
    "    for monograma in cont_monogramas[ttkn]:\n",
    "        prob_monogramas[ttkn][monograma] = cont_monogramas[ttkn][monograma] / apar_monogramas[ttkn]\n",
    "for ttkn in prob_monogramas:\n",
    "    maximos = [monograma.replace(\"\\n\", \" \") for monograma in sorted(prob_monogramas[ttkn], key=lambda x: prob_monogramas[ttkn][x], reverse=True)[:10]]\n",
    "    print(f\"Para {K.TTKN_DESC[ttkn].rjust(15)}: {', '.join([f'<{x}>: {round(prob_monogramas[ttkn][x], 7)}' for x in maximos])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Fragmentando ...||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "            Fragmentando 915608 n-gramas de Letras...................................................................................................!\n",
      "         Fragmentando 3733 n-gramas de Separadores..................................................................................................!\n",
      "            Fragmentando 17216 n-gramas de Dígitos...................................................................................................!\n",
      "             Fragmentando 602 n-gramas de Símbolos......................................................................................!\n",
      "       Fragmentando 18109 n-gramas de Desconocidos...................................................................................................!\n",
      "             Fragmentando 6 n-gramas de Especiales......!\n"
     ]
    }
   ],
   "source": [
    "fragmentos = {ttkn: {} for ttkn in dic_ngramas}\n",
    "fragmentos_n_grama = {ttkn: {} for ttkn in dic_ngramas}\n",
    "print(f\"Fragmentando ...\".rjust(50) + \"\".join([\"|\"]*100))\n",
    "for ttkn in dic_ngramas:\n",
    "    print(f\"Fragmentando {len(dic_ngramas[ttkn])} n-gramas de {K.TTKN_DESC[ttkn]}\".rjust(50), end=\"\")\n",
    "    cada = 1+ len(dic_ngramas[ttkn]) // 100\n",
    "    cont = 0\n",
    "    for n_grama in dic_ngramas[ttkn]:\n",
    "        for l_n in range(2, len(n_grama) - 1):\n",
    "            for i_ini in range(len(n_grama) - l_n):\n",
    "                if n_grama[i_ini:i_ini+l_n] in fragmentos[ttkn]:\n",
    "                    fragmentos[ttkn][n_grama[i_ini:i_ini+l_n]] += 1\n",
    "                    if n_grama in fragmentos_n_grama[ttkn][n_grama[i_ini:i_ini+l_n]]:\n",
    "                        fragmentos_n_grama[ttkn][n_grama[i_ini:i_ini+l_n]][n_grama] += 1\n",
    "                    else:\n",
    "                        fragmentos_n_grama[ttkn][n_grama[i_ini:i_ini+l_n]][n_grama] = 1\n",
    "                else:\n",
    "                    fragmentos[ttkn][n_grama[i_ini:i_ini+l_n]] = 1\n",
    "                    fragmentos_n_grama[ttkn][n_grama[i_ini:i_ini+l_n]] = {n_grama: 1}\n",
    "        cont += 1\n",
    "        if cont % cada == 0:\n",
    "            print(\".\", end=\"\")\n",
    "    print(\"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragmentos óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acum_frag_n_grama = {ttkn: sum([len(fragmentos_n_grama[ttkn][x]) for x in fragmentos_n_grama[ttkn]]) for ttkn in fragmentos_n_grama}\n",
    "acum_fragmentos = {ttkn: sum([fragmentos[ttkn][x] for x in fragmentos[ttkn]]) for ttkn in fragmentos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Evaluando fragmentos sobre tokens ...||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Ordenando 4010068 fragmentos de Letras...\n",
      "Evaluando 915608 n-gramas de Letras cada 9157 un punto."
     ]
    }
   ],
   "source": [
    "fragmentos_usados = {ttkn: {} for ttkn in fragmentos}\n",
    "excedentes = {ttkn: {} for ttkn in fragmentos}\n",
    "fragmentos_evaluados = {}\n",
    "print(f\"Evaluando fragmentos sobre tokens ...\".rjust(50) + \"\".join([\"|\"]*100))\n",
    "for ttkn in dic_ngramas:\n",
    "    print(f\"Ordenando {len(fragmentos[ttkn])} fragmentos de {K.TTKN_DESC[ttkn]}...\")\n",
    "    fragmentos_evaluados[ttkn] = sorted(\n",
    "        fragmentos[ttkn],\n",
    "        key=lambda x: len(x) * (fragmentos[ttkn][x] / acum_fragmentos[ttkn]) * (len(fragmentos_n_grama[ttkn][x]) /acum_frag_n_grama[ttkn] ),\n",
    "        reverse=True\n",
    "    )\n",
    "    cada = 1+ len(dic_ngramas[ttkn]) // 100\n",
    "    print(f\"Evaluando {len(dic_ngramas[ttkn])} n-gramas de {K.TTKN_DESC[ttkn]} cada {cada} un punto.\".rjust(50), end=\"\")\n",
    "    cont = 0\n",
    "    for n_grama in dic_ngramas[ttkn]:\n",
    "        if isinstance(n_grama, str):\n",
    "            invent.explota_fragmento(n_grama, fragmentos_usados[ttkn], excedentes[ttkn], fragmentos_evaluados[ttkn])\n",
    "        cont += 1\n",
    "        if cont % cada == 0:\n",
    "            print(\".\", end=\"\")\n",
    "    print(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragmentos_usados_path = r\"D:\\datos\\tokens_usados.pkl\"\n",
    "excedentes_path = r\"D:\\datos\\tokens_excedentes.pkl\"\n",
    "fragmentos_evaluados_path = r\"D:\\datos\\tokens_evaluados.pkl\"\n",
    "print(f\"Guardando {fragmentos_usados_path}\")\n",
    "with open(fragmentos_usados_path, \"wb\") as file:\n",
    "    pickle.dump(fragmentos_usados)\n",
    "print(f\"Guardando {excedentes_path}\")\n",
    "with open(excedentes_path, \"wb\") as file:\n",
    "    pickle.dump(excedentes)\n",
    "print(f\"Guardando {fragmentos_evaluados_path}\")\n",
    "with open(fragmentos_evaluados_path, \"wb\") as file:\n",
    "    pickle.dump(fragmentos_evaluados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {K.TTKN_SIS:token_id for token_id in K.MAIN_TOKEN_DICT} + {ttkn: {} for ttkn in fragmentos}\n",
    "token_id = 10\n",
    "for ttkn in fragmentos_evaluados:\n",
    "    token_id += 1000 * ttkn\n",
    "    for fragmento in fragmentos_evaluados[ttkn]:\n",
    "        if fragmento in fragmentos_usados[ttkn]:\n",
    "            tokens[ttkn][fragmento] = token_id\n",
    "            token_id += 1\n",
    "    for excedente in excedentes[ttkn]:\n",
    "        tokens[ttkn][excedente] = token_id\n",
    "        token_id += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos un total de 89269666 apariciones de 589563 n-gramas\n",
      "Una media de 151 apariciones/n-grama\n",
      "El n-grama que menos veces aparece es 'hebestreit' con 1 veces\n",
      "El n-grama que MÁS veces aparece es ' ' con 35692569 veces\n"
     ]
    }
   ],
   "source": [
    "num_ngramas = len(n_gramas)\n",
    "acum_ngramas = 0\n",
    "min_apariciones = 10000000\n",
    "min_ngrama = \"\"\n",
    "max_apariciones = 0\n",
    "max_ngrama = \"\"\n",
    "for n_grama in n_gramas:\n",
    "    acum_ngramas += n_gramas[n_grama]\n",
    "    if n_gramas[n_grama] < min_apariciones:\n",
    "        min_apariciones = n_gramas[n_grama]\n",
    "        min_ngrama = n_grama\n",
    "    if n_gramas[n_grama] > max_apariciones:\n",
    "        max_apariciones = n_gramas[n_grama]\n",
    "        max_ngrama = n_grama\n",
    "print(f\"Tenemos un total de {acum_ngramas} apariciones de {num_ngramas} n-gramas\")\n",
    "print(f\"Una media de {round(acum_ngramas/num_ngramas)} apariciones/n-grama\")\n",
    "print(f\"El n-grama que menos veces aparece es '{min_ngrama}' con {min_apariciones} veces\")\n",
    "print(f\"El n-grama que MÁS veces aparece es '{max_ngrama}' con {max_apariciones} veces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ngramas = {}\n",
    "pond_len_ngrama = {}\n",
    "acum_pond_ngramas = 0\n",
    "for n_grama in n_gramas:\n",
    "    prob_ngramas[n_grama] = n_gramas[n_grama] / num_ngramas\n",
    "    pond_len_ngrama[n_grama] = len(n_grama) * n_gramas[n_grama]\n",
    "    acum_pond_ngramas += pond_len_ngrama[n_grama]\n",
    "prob_pond_ngramas = {}\n",
    "for n_grama in pond_len_ngrama:\n",
    "    prob_pond_ngramas[n_grama] = pond_len_ngrama[n_grama] / acum_pond_ngramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ngrama '<|CAP|>'          Ngrama ' '         Ngrama 'de'  Ngrama '<|UPPER|>'         Ngrama 'la'         Ngrama ', '\n",
      "         Ngrama 'en'         Ngrama 'el'        Ngrama 'que'        Ngrama ' , '        Ngrama 'los'        Ngrama 'del'\n",
      "         Ngrama '. '        Ngrama 'por'        Ngrama 'con'        Ngrama 'una'          Ngrama 'y'        Ngrama 'las'\n",
      "       Ngrama 'para'         Ngrama 'se'       Ngrama 'como'         Ngrama 'un'          Ngrama 'a'         Ngrama 'su'\n",
      "        Ngrama 'fue'    Ngrama 'también'        Ngrama ' . '         Ngrama 'es'         Ngrama 'al'         Ngrama '  '\n",
      "      Ngrama 'entre'    Ngrama 'durante'        Ngrama 'más'    Ngrama 'después'          Ngrama '('        Ngrama '.  '\n",
      "        Ngrama 'sus'          Ngrama ')'    Ngrama 'primera'      Ngrama 'desde'      Ngrama 'hasta'      Ngrama 'sobre'\n",
      "       Ngrama 'este'  Ngrama 'población'     Ngrama 'ciudad'      Ngrama 'parte'     Ngrama 'cuando'      Ngrama 'donde'\n",
      "Ngrama 'universidad'         Ngrama 'no'       Ngrama 'años'   Ngrama 'nacional'       Ngrama 'pero'  Ngrama 'encuentra'\n",
      "       Ngrama 'esta'     Ngrama 'fueron'     Ngrama 'primer'   Ngrama 'mientras'          Ngrama '-'         Ngrama 'lo'\n",
      "        Ngrama 'dos'  Ngrama 'temporada'  Ngrama 'municipio'Ngrama 'estadounidense'    Ngrama 'estados' Ngrama 'septiembre'\n",
      "     Ngrama 'nombre'     Ngrama 'estado'    Ngrama 'familia'Ngrama 'internacional' Ngrama 'habitantes'      Ngrama 'había'\n",
      "      Ngrama 'tiene'   Ngrama 'gobierno'    Ngrama 'partido'    Ngrama 'general'       Ngrama 'está'      Ngrama 'otros'\n",
      "        Ngrama 'son'     Ngrama 'además'   Ngrama 'historia'Ngrama 'posteriormente'    Ngrama 'embargo'        Ngrama 'año'\n",
      " Ngrama 'presidente'     Ngrama 'contra'     Ngrama 'aunque'  Ngrama 'diciembre'   Ngrama 'personas'  Ngrama 'noviembre'\n",
      "     Ngrama 'guerra'        Ngrama 'era'     Ngrama 'equipo'      Ngrama 'mismo'      Ngrama 'puede'         Ngrama ' \"'\n",
      "    Ngrama 'segunda'     Ngrama 'tiempo'        Ngrama 'sin'  Ngrama 'provincia'       Ngrama 'gran'"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for n_grama in sorted(prob_pond_ngramas, key=lambda x:prob_pond_ngramas[x], reverse=True ):\n",
    "    p_ngrama = n_grama.replace(\"\\n\", \"¬\")\n",
    "    print(f\"Ngrama '{p_ngrama}'\".rjust(20), end=\"\")\n",
    "    cont += 1\n",
    "    if cont % 6 == 0:\n",
    "        print()\n",
    "    if cont > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n-grama más largo tiene 217 caracteres: '                                                                                                                                                                                                                         '\n",
      "217 <|                                                                                                                                                                                                                         |>\n",
      "209 <|                                                                                                                                                                                                                 |>\n",
      "200 <|                                                                                                                                                                                                        |>\n",
      "186 <|.                                                                                                                                                                                         |>\n",
      "175 <|                                                                                                                                                                               |>\n",
      "141 <|,\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;|>\n",
      "127 <|                                                                                                                               |>\n",
      "124 <|.                                                                                                                           |>\n",
      "116 <|.                                                                                                                   |>\n",
      "110 <|+.                                                                                                            |>\n",
      " 82 <|  ,                                                                               |>\n",
      " 79 <| .                                                                             |>\n",
      " 76 <|6086555670238378989670371734243169622657830773351885970528324860512791691264|>\n",
      " 71 <|.                                                                     ¬|>\n",
      "  1 <| |>\n",
      " 52 <|:¬                                                  |>\n",
      " 48 <|cliominervareflexionestrayectoriaescuelahistoria|>\n",
      " 46 <|                                              |>\n",
      " 46 <|funcionesyclasificaciondelascelulasdendriticas|>\n",
      " 45 <|                                             |>\n",
      " 45 <|paraunsistemadelaprotecciónpenaldelpatrimonio|>\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_len_ngrama = \"\"\n",
    "for n_grama in n_gramas:\n",
    "    if len(n_grama) > max_len:\n",
    "        max_len = len(n_grama)\n",
    "        max_len_ngrama = n_grama\n",
    "print(f\"El n-grama más largo tiene {max_len} caracteres: '{max_len_ngrama}'\")\n",
    "cont = 0\n",
    "for n_grama in sorted(n_gramas, key=lambda x: len(x)+prob_ngramas[x], reverse=True):\n",
    "    p_ngrama = n_grama.replace(\"\\n\", \"¬\")\n",
    "    print(f\"{str(len(n_grama)).rjust(3)} <|{p_ngrama}|>\")\n",
    "    cont += 1\n",
    "    if cont > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fragmentos\n",
    "Contamos trozos de n-grama distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos por el n_grama 580000 de 589563\n",
      "Generados 2545350 fragmentos de n-grama\n"
     ]
    }
   ],
   "source": [
    "limite = 50 # Máximo número de caracteres admitidos\n",
    "fragmentos = {}\n",
    "fragmento_n_grama = {}\n",
    "proto_fragmentos = []\n",
    "cont = 0\n",
    "print(f\"Fragmentando {len(n_gramas)} n-gramas\")\n",
    "for n_grama in n_gramas:\n",
    "    pre_fragmento = \"\" + n_grama\n",
    "    while len(pre_fragmento) > limite:\n",
    "        if pre_fragmento[:limite] not in proto_fragmentos:\n",
    "            proto_fragmentos.append(pre_fragmento[:limite])\n",
    "        pre_fragmento = pre_fragmento[limite:]\n",
    "    if pre_fragmento > \"\" and pre_fragmento not in proto_fragmentos:\n",
    "        proto_fragmentos.append(pre_fragmento)\n",
    "    cont += 1\n",
    "    if cont % 10000 == 0:\n",
    "        clear_output()\n",
    "        print(f\"Vamos por el n_grama {cont} de {len(n_gramas)}\")\n",
    "print(f\"... troceando {len(proto_fragmentos)} n-gramas\")\n",
    "cont = 0\n",
    "for n_grama in proto_fragmentos:\n",
    "    if cont == 0:\n",
    "        print(f\"Fragmentados {cont} n-gramas de {len(proto_fragmentos)}\")\n",
    "    for l_n in range(2, len(n_grama) - 1):\n",
    "        for i_ini in range(len(n_grama) - l_n):\n",
    "            if n_grama[i_ini:i_ini+l_n] in fragmentos:\n",
    "                fragmentos[n_grama[i_ini:i_ini+l_n]] += 1\n",
    "                if n_grama in fragmento_n_grama[n_grama[i_ini:i_ini+l_n]]:\n",
    "                    fragmento_n_grama[n_grama[i_ini:i_ini+l_n]][n_grama] += 1\n",
    "                else:\n",
    "                    fragmento_n_grama[n_grama[i_ini:i_ini+l_n]][n_grama] = 1\n",
    "            else:\n",
    "                fragmentos[n_grama[i_ini:i_ini+l_n]] = 1\n",
    "                fragmento_n_grama[n_grama[i_ini:i_ini+l_n]] = {n_grama: 1}\n",
    "    cont += 1\n",
    "    if cont % 10000 == 0:\n",
    "        clear_output()\n",
    "        print(f\"Vamos por el n_grama {cont} de {len(proto_fragmentos)}\")\n",
    "del proto_fragmentos\n",
    "print(f\"Generados {len(fragmentos)} fragmentos de n-grama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 2545350 fragmentos con un total de 14698314 apariciones\n",
      "Hay 14621202 n-gramas con 5.74 n-gramas por fragmento de media\n",
      "El fragmento 'ar' es el que aparece en más n_gramas con 63612 n-gramas\n"
     ]
    }
   ],
   "source": [
    "acum_fragmentos_in_ngramas = 0\n",
    "cont_fragmentos_in_ngramas = 0\n",
    "max_fragmentos_in_ngramas = 0\n",
    "max_fragmentos_in_ngramas_fragmento = \"\"\n",
    "for fragmento in fragmento_n_grama:\n",
    "    acum_fragmentos_in_ngramas += len(fragmento_n_grama[fragmento])\n",
    "    cont_fragmentos_in_ngramas += sum([fragmento_n_grama[fragmento][x] for x in fragmento_n_grama[fragmento]])\n",
    "    if len(fragmento_n_grama[fragmento]) > max_fragmentos_in_ngramas:\n",
    "        max_fragmentos_in_ngramas = len(fragmento_n_grama[fragmento])\n",
    "        max_fragmentos_in_ngramas_fragmento = fragmento\n",
    "print(f\"Tenemos {len(fragmentos)} fragmentos con un total de {cont_fragmentos_in_ngramas} apariciones\")\n",
    "print(f\"Hay {acum_fragmentos_in_ngramas} n-gramas con {round(acum_fragmentos_in_ngramas / len(fragmentos), 2)} n-gramas por fragmento de media\")\n",
    "print(f\"El fragmento '{max_fragmentos_in_ngramas_fragmento}' es el que aparece en más n_gramas con {max_fragmentos_in_ngramas} n-gramas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_fragmentos = {}\n",
    "for fragmento in fragmento_n_grama:\n",
    "    prob_fragmentos[fragmento] = sum([fragmento_n_grama[fragmento][x] for x in fragmento_n_grama[fragmento]]) / cont_fragmentos_in_ngramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fragmentos usados\n",
    "Contamos los fragmentos de n-grama para ver su relación entre relevancia e información\n",
    "- Se trata de ordenar los fragmentos según tengan más información y se repitan más veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minima-mente está en {minima_mente}\n",
      "Tenemos 9926 fragmentos seleccionados\n",
      "'alizació'           'ticament'           'ificació'           'presenta'           'american'           'tivament'           'acionali'           'structur'           \n",
      "'icament'            'lizació'            'ográfic'            'alizaci'            'acional'            'ificaci'            'electro'            'cionali'            \n",
      "'amiento'            'present'            'ificado'            'ecciona'            'adament'            'ológica'            'alizado'            'abilida'            \n",
      "'ticamen'            'ntement'            'ivament'            'ficació'            'constru'            'resenta'            'america'            'ferenci'            \n",
      "'tacione'            'rizació'            'ministr'            'termina'            'namient'            'naciona'            'osament'            'merican'            \n",
      "'cionale'            'olucion'            'cimient'            'erencia'            'racione'            'estruct'            'ológico'            'blement'            \n",
      "'cionist'            'tivamen'            'mentari'            'tológic'            'onaliza'            'organiz'            'ométric'            'structu'            \n",
      "'tructur'            'interpr'            'entemen'            'histori'            'bacteri'            'acione'             'amient'             'izació'             \n",
      "'contra'             '      '             'ológic'             'cament'             'icamen'             'iéndol'             'alizad'             'ificad'             \n",
      "'aciona'             'cional'             'alment'             'tifica'             'tándol'             'cciona'             'lizaci'             'pseudo'             \n",
      "'cionar'             'gráfic'             'electr'             'imient'             'miento'             'mentar'             'ándolo'             'eccion'             \n",
      "'ificar'             'bilida'             'dament'             'lement'             'ionali'             'ográfi'             'alizar'             'iéndos'             \n",
      "'cionad'             'naliza'             'lizado'             'presen'             'alizac'             'lectro'             'icació'             'nifica'             \n",
      "'imenta'             'interc'             'racion'             'ficaci'             'iciona'             'ificac'             'lacion'             'resent'             \n",
      "'tacion'             'nacion'             'métric'             'descon'             'minist'             'raliza'             'rándol'             'osauru'             \n",
      "'struct'             'sifica'             'termin'             'interp'             'alista'             'ionist'             'hetero'             'amenta'             \n",
      "'genera'             'ionale'             'ficado'             'iforme'             'nstitu'             'transf'             'erenci'             'ializa'             \n",
      "'esiona'             'constr'             'taliza'             'entari'             'ándola'             'ografí'             'rifica'             'lógica'             \n",
      "'centra'             'produc'             'tement'             'cionis'             'osauri'             'transp'             'organi'             'tament'             \n",
      "'sament'             'adamen'             'onstru'             'abilid'             'vament'             'americ'             'ntemen'             'tándos'             \n",
      "'cultur'             'ticame'             'difica'             'mentad'             'accion'             'castel'             'contin'             'ermina'             \n",
      "'ivamen'             'nciona'             'ferenc'             'rizaci'             'nándol'             'entado'             'ionari'             'scribi'             \n",
      "'dicion'             'merica'             'acteri'             'izador'             'uciona'             'biliza'             'respon'             'comple'             \n",
      "'comuni'             'inistr'             'ualiza'             'umenta'             'transm'             'izándo'             'esenta'             'compar'             \n",
      "'caliza'             'ograph'             'rencia'             'sionar'             'onaliz'             'cándol'             'diéndo'             'ntific'             \n",
      "'mental'             'tabili'             'icándo'             'integr'             'ionado'             'nuncia'             'public'             'ciéndo'             \n",
      "'escrib'             'estruc'             'istori'             'lógico'             'erican'             'sionad'             'ntándo'             'namien'             \n",
      "'lucion'             'ementa'             'osamen'             'ándole'             'conver'             'olucio'             'lifica'             'cimien'             \n",
      "'cacion'             'astell'             'repres'             'nizaci'             'lament'             'zándol'             'person'             'olític'             \n",
      "'blemen'             'cializ'             'histor'             'ilizad'             'labora'             'posici'             'bilita'             'tivame'             \n",
      "'lizada'             'lariza'             'rándos'             'tiliza'             'orizad'             'multip'             'ndosel'             'nforma'             \n",
      "'sibili'             'ccione'             'nterpr'             'distri'             'entali'             'cephal'             'especi'             'rganiz'             \n",
      "'atoria'             'tadore'             'tológi'             'indica'             'bacter'             'libera'             'capita'             'ométri'             \n",
      "'abiliz'             'izacio'             'voluci'             'lizarl'             'onalis'             'guarda'             'ogénic'             'intern'             \n",
      "'encion'             'crimin'             'onista'             'tructu'             'interr'             'ranqui'             'matiza'             'inform'             \n",
      "'planta'             'nomina'             'graphi'             'partic'             'ructur'             'univer'             'establ'             'transc'             \n",
      "'ografi'             'superc'             'script'             'ticula'             'nivers'             'activa'             'tivida'             'corpor'             \n",
      "'enteme'             'ension'             'rament'             'ntegra'             'ordina'             'prendi'             'contro'             'estion'             \n",
      "'asific'             'abilit'             'plemen'             'christ'             'ristia'             'istian'             'descar'             'ament'              \n",
      "'ándol'              'inter'              'ciona'              'acion'              'ifica'              'aliza'              'cione'              'mient'              \n",
      "'trans'              'ándos'              'menta'              'contr'              'adore'              'amien'              'izaci'              'iéndo'              \n",
      "'super'              '     '              'zació'              'lizad'              'encia'              'ontra'              'micro'              'lógic'              \n",
      "'ement'              'entar'              'ional'              'ológi'              'siona'              'éndol'              'ccion'              'izado'              \n",
      "'ionar'              'camen'              'tándo'              'multi'              'atori'              'alist'              'icame'              'sobre'              \n",
      "'villa'              'tific'              'abili'              'ístic'              'ficad'              'alida'              'porta'              'entad'              \n",
      "'adora'              'ologí'              'ionad'              'lizar'              'almen'              'osaur'              'parti'              'elect'              \n",
      "'lment'              'iliza'              'centr'              'const'              'forma'              'iform'              'compa'              'icion'              \n",
      "'ndolo'              'iment'              'hidro'              'mátic'              'recon'              'stitu'              'pseud'              'onali'              \n",
      "'lista'              'entre'              'ilida'              'rándo'              'icaci'              'seudo'              'rista'              'lectr'              \n",
      "'lizac'              'iento'              'desco'              'ation'              'entra'              'rizad'              'extra'              'estra'              \n",
      "'oriza'              "
     ]
    }
   ],
   "source": [
    "minima_mente = min([\n",
    "    len(fragmento_n_grama[\"mente\"])/acum_fragmentos_in_ngramas if \"mente\" in fragmento_n_grama else 0.0,\n",
    "    len(fragmento_n_grama[\"ndo\"])/acum_fragmentos_in_ngramas if \"ndo\" in fragmento_n_grama else 0.0,\n",
    "    len(fragmento_n_grama[\"ido\"])/acum_fragmentos_in_ngramas if \"ido\" in fragmento_n_grama else 0.0\n",
    "])\n",
    "print(\"Minima-mente está en {minima_mente}\")\n",
    "fragmentos_ok = [x for x in fragmentos if len(fragmento_n_grama[x])/acum_fragmentos_in_ngramas >= minima_mente]\n",
    "print(f\"Tenemos {len(fragmentos_ok)} fragmentos seleccionados\")\n",
    "cont = 0\n",
    "for fragmento in sorted(fragmentos_ok, key=lambda x: len(x) + prob_fragmentos[x] + len(fragmento_n_grama[x])/acum_fragmentos_in_ngramas, reverse=True):\n",
    "    p_frag = fragmento.replace(\"\\n\", \"¬\")\n",
    "    print(f\"'{p_frag}'\".ljust(20), end=\" \")\n",
    "    cont += 1\n",
    "    if cont % 8 == 0:\n",
    "        print()\n",
    "    if cont > 400:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exprime_fragmento(n_grama, fragmentos_usados, excedentes, fragmentos_evaluados):\n",
    "    cont_excedentes = 1\n",
    "    cont_sub_excedentes = 0\n",
    "    for fragmento in fragmentos_evaluados:\n",
    "        if len(fragmento) > len(n_grama):\n",
    "            continue\n",
    "        elif fragmento == n_grama:\n",
    "            cont_excedentes = 0  # contador a cero\n",
    "            if fragmento in fragmentos_usados:\n",
    "                fragmentos_usados[fragmento] += 1\n",
    "            else:\n",
    "                fragmentos_usados[fragmento] = 1\n",
    "        elif fragmento in n_grama:\n",
    "            cont_excedentes = 0\n",
    "            if fragmento in fragmentos_usados:\n",
    "                fragmentos_usados[fragmento] += 1\n",
    "            else:\n",
    "                fragmentos_usados[fragmento] = 1\n",
    "            for x in n_grama.split(fragmento):\n",
    "                if x and x > \"\":\n",
    "                    cont_sub_excedentes += exprime_fragmento(x, fragmentos_usados, excedentes, fragmentos_evaluados)\n",
    "            break\n",
    "    if cont_excedentes > 0:\n",
    "        if n_grama in excedentes:\n",
    "            excedentes[n_grama] += 1\n",
    "        else:\n",
    "            excedentes[n_grama] = 1\n",
    "    return cont_excedentes + cont_sub_excedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llevamos 580000 de 589563\n",
      "9862 usados y 643460 generados...\n"
     ]
    }
   ],
   "source": [
    "fragmentos_evaluados = sorted(fragmentos_ok, key=lambda x: len(x) + prob_fragmentos[x] + len(fragmento_n_grama[x])/acum_fragmentos_in_ngramas, reverse=True)\n",
    "fragmentos_usados = {}\n",
    "excedentes = {}\n",
    "cont_usados = 0\n",
    "cont_excedentes = 0\n",
    "cont_existentes = 0\n",
    "cont = 0\n",
    "for n_grama in n_gramas:\n",
    "    cont_excedentes += exprime_fragmento(n_grama, fragmentos_usados, excedentes, fragmentos_evaluados)\n",
    "    cont += 1\n",
    "    if cont % 10000 == 0:\n",
    "        clear_output()\n",
    "        print(f\"Llevamos {cont} de {len(n_gramas)}\")\n",
    "        print(f\"{len(fragmentos_usados)} usados y {cont_excedentes} generados...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|os|>          <|as|>          <|es|>          <|re|>          <|an|>          <|in|>          <|on|>          <|us|>          <|en|>          <|al|>          \n",
      "<|co|>          <|se|>          <|er|>          <|ta|>          <|ar|>          <|do|>          <|de|>          <|ma|>          <|la|>          <|le|>          \n",
      "<|ca|>          <|ra|>          <|is|>          <|su|>          <|na|>          <|te|>          <|ba|>          <|ro|>          <|da|>          <|ch|>          \n",
      "<|or|>          <|to|>          <|sa|>          <|ón|>          <|ne|>          <|lo|>          <|um|>          <|mo|>          <|di|>          <|ka|>          \n",
      "<|ad|>          <|el|>          <|ur|>          <|án|>          <|no|>          <|li|>          <|ri|>          <|me|>          <|bo|>          <|ex|>          \n",
      "<|ti|>          <|pa|>          <|po|>          <|ni|>          <|si|>          <|so|>          <|ha|>          <|gu|>          <|des|>         <|ía|>          \n",
      "<|at|>          <|cu|>          <|ol|>          <|un|>          <|am|>          <|ia|>          <|ac|>          <|ge|>          <|ko|>          <|ga|>          \n",
      "<|vi|>          <|mi|>          <|ada|>         <|il|>          <|ru|>          <|pe|>          <|be|>          <|ul|>          <|ya|>          <|ci|>          \n",
      "<|lu|>          <|tu|>          <|he|>          <|ab|>          <|bi|>          <|ho|>          <|pi|>          <|za|>          <|go|>          <|va|>          \n",
      "<|hu|>          <|et|>          <|ce|>          <|ki|>          <|ado|>         <|st|>          <|ja|>          <|mu|>          <|hi|>          <|au|>          \n",
      "<|ag|>          <|bu|>          <|sh|>          <|les|>         <|sub|>         <|ic|>          <|ke|>          <|qu|>          <|ando|>        <|im|>          \n",
      "<|sk|>          <|man|>         <|anti|>        <|dos|>         <|it|>          <|ir|>          <|ante|>        <|ng|>          <|ve|>          <|ana|>         \n",
      "<|ense|>        <|io|>          <|nd|>          <|ot|>          <|th|>          <|ing|>         <|ut|>          <|ina|>         <|fi|>          <|land|>        \n",
      "<|du|>          <|ida|>         <|jo|>          <|ku|>          <|ed|>          <|aría|>        <|pro|>         <|iano|>        <|aran|>        <|aba|>         \n",
      "<|gi|>          <|arlo|>        <|br|>          <|son|>         <|cher|>        <|res|>         <|pu|>          <|ella|>        <|em|>          <|fa|>          \n",
      "<|ju|>          <|ín|>          <|ap|>          <|pr|>          <|ara|>         <|con|>         <|das|>         <|ale|>         <|ll|>          <|sha|>         \n",
      "<|ron|>         <|zo|>          <|je|>          <|pre|>         <|ban|>         <|inter|>       <|ano|>         <|tico|>        <|tr|>          <|ob|>          \n",
      "<|ría|>         <|dis|>         <|ec|>          <|encia|>       <|able|>        <|ov|>          <|ero|>         <|ita|>         <|elle|>        <|adora|>       \n",
      "<|vo|>          <|ung|>         <|hy|>          <|ndo|>         <|ts|>          <|aban|>        <|oc|>          <|ido|>         <|sen|>         <|wa|>          \n",
      "<|ista|>        <|poli|>        <|amiento|>     <|mos|>         <|illo|>        <|ble|>         <|tica|>        <|ata|>         <|que|>         <|auto|>        \n",
      "<|fe|>          "
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for fragmento in sorted(fragmentos_usados, key=lambda x:fragmentos_usados[x], reverse=True):\n",
    "    p_frag = fragmento.replace(\"\\n\", \"¬\")\n",
    "    print(f\"<|{p_frag}|>\".ljust(15), end=\" \")\n",
    "    cont += 1\n",
    "    if cont % 10 == 0:\n",
    "        print()\n",
    "    if cont > 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|,\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;|> <|\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;|> <|&&&&&&&&&&&&&|> <|&&&&&&&&&&&&|> <|&&&&&&&&&&&|> <|&&&&&&&&&&|>  <|----------|>  <|<|UPPER|>|>   <|&&&&&&&&&|>   <| _______ |>   \n",
      "<| ______ |>    <|}}})}}}}|>    <|&&&&&&&&|>    <|<|CAP|>|>     <|wjbqfvz|>     <| ' ' ' |>     <| \\ +\\ \\|>     <|?!!!??!|>     <| + + + |>     <| ______|>     \n",
      "<|\\\\\\ \\ \\|>     <| ++ / |>      <| ' ' '|>      <|' / ' |>      <|\\\\:\\\\\\|>      <| ' '- |>      <| \\ \\ \\|>      <|}}}}}}|>      <|?????)|>      <|}}}}}{|>      \n",
      "<|(¿?!¡)|>      <|}})}}}|>      <|}}|}}}|>      <|}}]]]}|>      <|})}}}}|>      <|[????]|>      <|---- /|>      <|---- |>       <|&&&&&|>       <| / ; |>       \n",
      "<|{}}&{|>       <| '+' |>       <|}}}{(|>       <|}}}}}|>       <|\\\\:\\\\|>       <| +/- |>       <|}}{({|>       <|})}{{|>       <|}})}{|>       <|\\ +\\ |>       \n",
      "<|}}}~{|>       <|\\ \\ \\|>       <| \\ \\ |>       <|,\\;\\;|>       <| ''' |>       <|}}))}|>       <|; '' |>       <|}}}}{|>       <|}}}{{|>       <| ___ |>       \n",
      "<|)}}}}|>       <| + + |>       <|}}}}(|>       <|!}}&{|>       <|hxjvx|>       <|)}}}{|>       <| + / |>       <|}|}}}|>       <|',\\ \\|>       <|.¬¬¬¬|>       \n",
      "<|]}}}}|>       <|}}<{{|>       <|.¬¬- |>       <|'''''|>       <| + ; |>       <|@@@@@|>       <| \\\\\\\\|>       <|.,:_-|>       <|yüsüp|>       <|}}}<{|>       \n",
      "<|'' ; |>       <|)!}}}|>       <|\\\\-\\,|>       <|}}{|{|>       <|}})}}|>       <|yóújf|>       <|¬¬¬¬¬|>       <|\\;/\\;|>       <| ' ' |>       <|})}}}|>       \n",
      "<|++ ; |>       <| ' ; |>       <|}}}(||>       <|!!!!!|>       <|}}})}|>       <|}}}{|>        <|})}{|>        <| '' |>        <|,\\,\\|>        <|/ ; |>        \n",
      "<|}}{{|>        <|}}}}|>        <|}<({|>        <|]]]]|>        <|(¿?)|>        <|nüüd|>        <| '; |>        <|\\ \\,|>        <|qbfc|>        <| // |>        \n",
      "<|+ ; |>        <|}))}|>        <|\\;\\;|>        <|,\\;\\|>        <| \\\\\\|>        <|{})}|>        <|cfcf|>        <|.¬- |>        <|,¬- |>        <|}}&{|>        \n",
      "<|}})}|>        <| \\ \\|>        <|)}}}|>        <|,' '|>        <| ; '|>        <|}}|}|>        <|}}({|>        <|rxvt|>        <|//¬\"|>        <|.//¬|>        \n",
      "<| __ |>        <|.¬.-|>        <|yükç|>        <|\\,,\\|>        <|kújv|>        <| + /|>        <|-.¬\"|>        <| ¬- |>        <|:¬- |>        <|}}[[|>        \n",
      "<|}]]}|>        <| +/-|>        <|' ' |>        <|}}})|>        <|})}<|>        <|})}}|>        <|wwwf|>        <|}))<|>        <|¬¬¬¬|>        <|cvbg|>        \n",
      "<|cvvv|>        <| '''|>        <|[[]]|>        <|cfpj|>        <| ' '|>        <|' ; |>        <|,,,.|>        <|.'' |>        <|jpüy|>        <|!!!!|>        \n",
      "<|jíjí|>        <|}]}||>        <|jézé|>        <| ++ |>        <|}}{(|>        <|\\ \\ |>        <|\":¬\"|>        <|'\\,\\|>        <| \\,\\|>        <|}}}(|>        \n",
      "<|,\\ \\|>        <|!}}&|>        <|)!}}|>        <|}})(|>        <|}})]|>        <|}}))|>        <|}})[|>        <|;\\ \\|>        <|wwfx|>        <|????|>        \n",
      "<|.- '|>        <|.\"; |>        <| '\\,|>        <|\\\\\\\\|>        <|.¬ ¬|>        <|¿¿¿¿|>        <|'',\\|>        <| \\\\-|>        <|}]{{|>        <| / /|>        \n",
      "<|.\"/ |>        <|:///|>        <|''' |>        <|düzü|>        <|}}{[|>        <|]}{[|>        <|,'\\ |>        <|.' '|>        <|,+,\\|>        <|cwfc|>        \n",
      "<| +.¬|>        "
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for fragmento in sorted(excedentes, key=lambda x:len(x), reverse=True):\n",
    "    p_frag = fragmento.replace(\"\\n\", \"¬\")\n",
    "    if fragmento in fragmentos_usados:\n",
    "        p_frag = \" EXISTENTE: \" + p_frag\n",
    "    print(f\"<|{p_frag}|>\".ljust(15), end=\" \")\n",
    "    cont += 1\n",
    "    if cont % 10 == 0:\n",
    "        print()\n",
    "    if cont > 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetimos con 2545350 restos\n"
     ]
    }
   ],
   "source": [
    "fragmentos_re_evaluados = sorted([x for x in fragmentos if fragmento not in fragmentos_usados], key=lambda x: len(x) + prob_fragmentos[x] + len(fragmento_n_grama[x])/acum_fragmentos_in_ngramas, reverse=True)\n",
    "print(f\"Repetimos con {len(fragmentos_re_evaluados)} restos\")\n",
    "fragmentos_reusados = {}\n",
    "nuevos_excedentes = {}\n",
    "cont_excedentes = 0\n",
    "for n_grama in excedentes:\n",
    "    cont_excedentes += exprime_fragmento(n_grama, fragmentos_reusados, nuevos_excedentes, fragmentos_re_evaluados)\n",
    "    cont += 1\n",
    "    if cont % 10000 == 0:\n",
    "        clear_output()\n",
    "        print(f\"Llevamos {cont} de {len(excedentes)}\")\n",
    "        print(f\"{len(fragmentos_reusados)} usados y {cont_excedentes} generados...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848\n",
      "<|\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;|> <|\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;|> <|;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;|> <|\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;|> <|;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;|> <|&&&&&&&&&&&|> <|&&&&&&&&&&|>  <|----------|>  <|&&&&&&&&&|>   <|---------|>   \n",
      "<|&&&&&&&&|>    <|<|UPPER|>     <|wjbqfvz|>     <| + + + |>     <| ______|>     <|\\\\\\ \\ \\|>     <|&&&&&&&|>     <|wjbqfv|>      <| ' ' '|>      <| + + +|>      \n",
      "<|______|>      <|}}})}}|>      <|\\\\\\ \\ |>      <|}})}}}|>      <|---- /|>      <|<|CAP|>       <|---- |>       <|&&&&&|>       <| ' ' |>       <|\\ +\\ |>       \n",
      "<| \\ +\\|>       <|\\ \\ \\|>       <| \\ \\ |>       <|,\\;\\;|>       <| ''' |>       <|?!!!?|>       <| + + |>       <|hxjvx|>       <|.¬¬¬¬|>       <|'''''|>       \n",
      "<|yüsüp|>       <|}})}}|>       <|yóújf|>       <|})}}}|>       <|}}})}|>       <|----|>        <| '' |>        <|&&&&|>        <|/ ; |>        <|}}}}|>        \n",
      "<| ++ |>        <|\\;\\;|>        <|,\\;\\|>        <|' / |>        <|}})}|>        <| \\ \\|>        <|)}}}|>        <|}}|}|>        <|\\\\:\\|>        <| ' '|>        \n",
      "<|yükç|>        <|\\ +\\|>        <|kújv|>        <|' ' |>        <|}}})|>        <|})}}|>        <|\\ \\ |>        <|¬¬¬¬|>        <|''' |>        <| '''|>        \n",
      "<|,,,.|>        <|.'' |>        <| ___|>        <|jézé|>        <| + +|>        <|hxjv|>        <|????|>        <|.\"; |>        <|}|}}|>        <| / /|>        \n",
      "<|.¬¬¬|>        <|''''|>        <|dújd|>        <|(¿?!|>        <|çükç|>        <|yüsü|>        <|--- |>        <|.¬._|>        <|zvvd|>        <|yóúj|>        \n",
      "<|____|>        <|+ + |>        <|}}]]|>        <| ; |>         <|fút|>         <| / |>         <|'; |>         <|\"; |>         <|.; |>         <|://|>         \n",
      "<|-- |>         <|}}{|>         <|}}}|>         <|}}&|>         <|\\\\\\|>         <|})}|>         <|)}{|>         <|wwf|>         <|.- |>         <|.¬\"|>         \n",
      "<|lxó|>         <|zúñ|>         <| ''|>         <|'' |>         <| + |>         <|süj|>         <|-; |>         <|lüb|>         <|wpb|>         <| ' |>         \n",
      "<|qqo|>         <|júp|>         <|!!!|>         <|+\\ |>         <|\\ \\|>         <|süd|>         <|++ |>         <|pbk|>         <|}}<|>         <|cwm|>         \n",
      "<|,\\,|>         <|dúz|>         <|jpb|>         <|gúa|>         <|.' |>         <|}}(|>         <|tüb|>         <|}})|>         <|bwc|>         <|fgv|>         \n",
      "<|]]]|>         <|lxv|>         <|' '|>         <|,' |>         <|.'\"|>         <|(¿?|>         <|cvb|>         <|---|>         <|¬- |>         <|.\"\"|>         \n",
      "<|wmv|>         <|újp|>         <|bfp|>         <|yük|>         <|wój|>         <|.--|>         <|cxd|>         <| ¬\"|>         <| //|>         <|.¬-|>         \n",
      "<|.¬¬|>         <|}))|>         <|'''|>         <|{}}|>         <|\\;\\|>         <|,\\;|>         <|kúj|>         <| '\"|>         <|fcf|>         <|hjk|>         \n",
      "<|cfz|>         <|júz|>         <| '+|>         <|kçe|>         <|¬-\"|>         <|bfg|>         <|sxs|>         <|\\\\-|>         <|,\\ |>         <| \\ |>         \n",
      "<|fcv|>         <|mxn|>         <|kút|>         <|}|}|>         <|açu|>         <| /.|>         <|vvv|>         <|çük|>         <|wjw|>         <|;; |>         \n",
      "<| _ |>         <|//¬|>         <|\\\\:|>         <|:\\\\|>         <| __|>         <|jvx|>         <|.¬.|>         <|\",\"|>         <| +/|>         <|üxs|>         \n",
      "<|aço|>         "
     ]
    }
   ],
   "source": [
    "print(len(fragmentos_reusados))\n",
    "cont = 0\n",
    "for fragmento in sorted(fragmentos_reusados, key=lambda x:len(x), reverse=True):\n",
    "    p_frag = fragmento.replace(\"\\n\", \"¬\")\n",
    "    if fragmento in fragmentos_usados:\n",
    "        p_frag = \" EXISTENTE: \" + p_frag\n",
    "    print(f\"<|{p_frag}|>\".ljust(15), end=\" \")\n",
    "    cont += 1\n",
    "    if cont % 10 == 0:\n",
    "        print()\n",
    "    if cont > 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5988\n",
      "<|(?)|>         <|[<]|>         <|<)>|>         <|($)|>         <|{{{|>         <|)]·|>         <|)](|>         <|(€)|>         <|)>(|>         <|)()|>         \n",
      "<|(%)|>         <|(|||>         <|(>)|>         <|)({|>         <|(!)|>         <|)([|>         <|]([|>         <|)·(|>         <|>{{|>         <|¡¡¡|>         \n",
      "<|'/'|>         <|(~)|>         <|&<<|>         <|{<}|>         <|···|>         <|)(?|>         <|({{|>         <|{{<|>         <|)(||>         <|)&{|>         \n",
      "<|]~[|>         <|(#)|>         <||>|>          <|%}|>          <|}@|>          <|){|>          <|%)|>          <|(¡|>          <|!)|>          <|:+|>          \n",
      "<|()|>          <|({|>          <|)&|>          <|[{|>          <|]?|>          <|&{|>          <|?)|>          <|)]|>          <|<<|>          <|($|>          \n",
      "<||||>          <||{|>          <|)(|>          <|º)|>          <|%%|>          <|[(|>          <|¬/|>          <|](|>          <|·(|>          <|[¡|>          \n",
      "<|([|>          <|{{|>          <|(#|>          <|¡(|>          <|(?|>          <|ª)|>          <|-¬|>          <|(@|>          <|(>|>          <|)[|>          \n",
      "<|][|>          <|&(|>          <|>&|>          <|(~|>          <|€)|>          <|¡¡|>          <|/_|>          <|~}|>          <|/+|>          <|)?|>          \n",
      "<|?&|>          <|$)|>          <|+-|>          <|]!|>          <|(<|>          <|]·|>          <|%!|>          <|)·|>          <|<!|>          <|º(|>          \n",
      "<|~)|>          <|,/|>          <|[¿|>          <|>)|>          <|-/|>          <||<|>          <|(%|>          <|~{|>          <|çá|>          <|çç|>          \n",
      "<|!{|>          <|:-|>          <|(€|>          <|[}|>          <|¿¡|>          <|º>|>          <|)<|>          <|€]|>          <|¡¿|>          <|?>|>          \n",
      "<|#!|>          <|<%|>          <|$>|>          <|$$|>          <|(·|>          <|)>|>          <|]||>          <|{[|>          <|!(|>          <|~#|>          \n",
      "<|##|>          <|<¡|>          <|!>|>          <|<}|>          <|<>|>          <|\\_|>          <|!~|>          <|$?|>          <|[>|>          <|(]|>          \n",
      "<|[<|>          <|%(|>          <||[|>          <|'/|>          <|(||>          <|/'|>          <|¿)|>          <|;-|>          <|#)|>          <|¡)|>          \n",
      "<|_-|>          <|#?|>          <|¿(|>          <|{<|>          <|&<|>          <|>||>          <|?¿|>          <|~!|>          <|¡!|>          <|(¬|>          \n",
      "<|)#|>          <|ª(|>          <|íw|>          <|º#|>          <|><|>          <|!¿|>          <|?¡|>          <|>[|>          <|,_|>          <|(º|>          \n",
      "<|%]|>          <|?}|>          <|dñ|>          <|s|>           <| |>           <|c|>           <|a|>           <|i|>           <|b|>           <|o|>           \n",
      "<|v|>           <|ó|>           <|1|>           <|j|>           <|:|>           <|.|>           <|m|>           <|(|>           <|+|>           <|3|>           \n",
      "<|)|>           <|l|>           <|e|>           <|d|>           <|y|>           <|n|>           <|r|>           <|t|>           <|u|>           <|-|>           \n",
      "<|2|>           <|f|>           <|p|>           <|g|>           <|h|>           <|9|>           <|ñ|>           <|5|>           <|6|>           <|í|>           \n",
      "<|z|>           "
     ]
    }
   ],
   "source": [
    "print(len(nuevos_excedentes))\n",
    "cont = 0\n",
    "for fragmento in sorted(nuevos_excedentes, key=lambda x:len(x), reverse=True):\n",
    "    p_frag = fragmento.replace(\"\\n\", \"¬\")\n",
    "    if fragmento in fragmentos_usados:\n",
    "        p_frag = \" EXISTENTE: \" + p_frag\n",
    "    print(f\"<|{p_frag}|>\".ljust(15), end=\" \")\n",
    "    cont += 1\n",
    "    if cont % 10 == 0:\n",
    "        print()\n",
    "    if cont > 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 16694 pre tokens\n"
     ]
    }
   ],
   "source": [
    "pre_tokens_id = {}\n",
    "token_id = 1\n",
    "for fragmento in fragmentos_evaluados:\n",
    "    if fragmento in fragmentos_usados:\n",
    "        pre_tokens_id[fragmento] = token_id\n",
    "        token_id += 1\n",
    "for fragmento in fragmentos_re_evaluados:\n",
    "    if fragmento in fragmentos_reusados:\n",
    "        pre_tokens_id[fragmento] = token_id\n",
    "        token_id += 1\n",
    "for fragmento in nuevos_excedentes:\n",
    "    pre_tokens_id[fragmento] = token_id\n",
    "    token_id += 1\n",
    "print(f\"Tenemos {len(pre_tokens_id)} pre tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|alizació|>    <|ticament|>    <|ificació|>    <|presenta|>    <|american|>    <|tivament|>    <|acionali|>    <|structur|>    <|icament|>     <|lizació|>     \n",
      "<|ográfic|>     <|alizaci|>     <|acional|>     <|ificaci|>     <|electro|>     <|cionali|>     <|amiento|>     <|present|>     <|ificado|>     <|ecciona|>     \n",
      "<|adament|>     <|ológica|>     <|alizado|>     <|abilida|>     <|ticamen|>     <|ntement|>     <|ivament|>     <|ficació|>     <|constru|>     <|resenta|>     \n",
      "<|america|>     <|ferenci|>     <|tacione|>     <|rizació|>     <|ministr|>     <|termina|>     <|namient|>     <|naciona|>     <|osament|>     <|merican|>     \n",
      "<|cionale|>     <|olucion|>     <|cimient|>     <|erencia|>     <|racione|>     <|estruct|>     <|ológico|>     <|blement|>     <|cionist|>     <|mentari|>     \n",
      "<|onaliza|>     <|organiz|>     <|ométric|>     <|structu|>     <|interpr|>     <|entemen|>     <|histori|>     <|bacteri|>     <|acione|>      <|amient|>      \n",
      "<|izació|>      <|contra|>      <|ológic|>      <|cament|>      <|icamen|>      <|iéndol|>      <|alizad|>      <|ificad|>      <|aciona|>      <|      |>      \n",
      "<|cional|>      <|alment|>      <|tifica|>      <|tándol|>      <|cciona|>      <|lizaci|>      <|pseudo|>      <|cionar|>      <|gráfic|>      <|electr|>      \n",
      "<|imient|>      <|miento|>      <|mentar|>      <|ándolo|>      <|eccion|>      <|ificar|>      <|bilida|>      <|dament|>      <|lement|>      <|ionali|>      \n",
      "<|ográfi|>      <|alizar|>      <|iéndos|>      <|cionad|>      <|naliza|>      <|lizado|>      <|presen|>      <|lectro|>      <|icació|>      <|nifica|>      \n",
      "<|imenta|>      <|interc|>      <|racion|>      <|ficaci|>      <|iciona|>      <|ificac|>      <|lacion|>      <|resent|>      <|tacion|>      <|nacion|>      \n",
      "<|métric|>      <|descon|>      <|minist|>      <|raliza|>      <|rándol|>      <|osauru|>      <|struct|>      <|sifica|>      <|termin|>      <|interp|>      \n",
      "<|alista|>      <|ionist|>      <|hetero|>      <|amenta|>      <|genera|>      <|ionale|>      <|ficado|>      <|iforme|>      <|nstitu|>      <|transf|>      \n",
      "<|erenci|>      <|ializa|>      <|esiona|>      <|constr|>      <|taliza|>      <|entari|>      <|ándola|>      <|ografí|>      <|rifica|>      <|lógica|>      \n",
      "<|centra|>      <|produc|>      <|tement|>      <|cionis|>      <|osauri|>      <|transp|>      <|organi|>      <|tament|>      <|sament|>      <|adamen|>      \n",
      "<|onstru|>      <|abilid|>      <|vament|>      <|americ|>      <|tándos|>      <|cultur|>      <|ticame|>      <|difica|>      <|mentad|>      <|accion|>      \n",
      "<|castel|>      <|contin|>      <|ermina|>      <|ivamen|>      <|nciona|>      <|ferenc|>      <|rizaci|>      <|nándol|>      <|entado|>      <|ionari|>      \n",
      "<|scribi|>      <|dicion|>      <|merica|>      <|acteri|>      <|izador|>      <|uciona|>      <|biliza|>      <|respon|>      <|comple|>      <|comuni|>      \n",
      "<|inistr|>      <|ualiza|>      <|umenta|>      <|transm|>      <|izándo|>      <|esenta|>      <|compar|>      <|caliza|>      <|ograph|>      <|rencia|>      \n",
      "<|sionar|>      <|onaliz|>      <|cándol|>      <|diéndo|>      <|ntific|>      <|mental|>      <|tabili|>      <|icándo|>      <|integr|>      <|ionado|>      \n",
      "<|nuncia|>      <|public|>      <|ciéndo|>      <|escrib|>      <|estruc|>      <|istori|>      <|lógico|>      <|erican|>      <|sionad|>      <|ntándo|>      \n",
      "<|lucion|>      <|ementa|>      <|ándole|>      <|conver|>      <|lifica|>      <|cacion|>      <|astell|>      <|repres|>      <|nizaci|>      <|lament|>      \n",
      "<|person|>      <|olític|>      <|cializ|>      <|histor|>      <|ilizad|>      <|labora|>      <|posici|>      <|bilita|>      <|tivame|>      <|lizada|>      \n",
      "<|lariza|>      <|rándos|>      <|tiliza|>      <|orizad|>      <|multip|>      <|ndosel|>      <|nforma|>      <|sibili|>      <|ccione|>      <|nterpr|>      \n",
      "<|distri|>      <|entali|>      <|cephal|>      <|especi|>      <|rganiz|>      <|atoria|>      <|tadore|>      <|tológi|>      <|indica|>      <|bacter|>      \n",
      "<|libera|>      <|capita|>      <|ométri|>      <|abiliz|>      <|izacio|>      <|voluci|>      <|lizarl|>      <|onalis|>      <|guarda|>      <|ogénic|>      \n",
      "<|intern|>      <|encion|>      <|crimin|>      <|onista|>      <|interr|>      <|ranqui|>      <|matiza|>      <|inform|>      <|planta|>      <|nomina|>      \n",
      "<|graphi|>      <|partic|>      <|univer|>      <|establ|>      <|transc|>      <|ografi|>      <|superc|>      <|script|>      <|ticula|>      <|nivers|>      \n",
      "<|activa|>      <|tivida|>      <|corpor|>      <|enteme|>      <|ension|>      <|rament|>      <|ntegra|>      <|ordina|>      <|prendi|>      <|contro|>      \n",
      "<|estion|>      <|asific|>      <|abilit|>      <|plemen|>      <|christ|>      <|ristia|>      <|istian|>      <|descar|>      <|ament|>       <|ándol|>       \n",
      "<|inter|>       "
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for token in pre_tokens_id:\n",
    "    p_token = token.replace(\"\\n\", \"¬\")\n",
    "    print(f\"<|{p_token}|>\".ljust(15), end=\" \")\n",
    "    cont += 1\n",
    "    if cont % 10 == 0:\n",
    "        print()\n",
    "    if cont > 300:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
